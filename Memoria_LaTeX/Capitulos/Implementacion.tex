\chapter{Implementación de la herramienta}
\label{cap:implementacion}

En esta sección se contará los detalles de la implementación especificando la implementación de cada modulo y cada uno de los tests.  
Para la implementación de la herramienta se ha decidido utilizar \emph{C++} como lenguaje de programación, el OCR elegido(Tesseract) proporciona api en \emph{C++}. Docker es una plataforma de código abierto que permite el despliegue de una aplicación en un contenedor, donde solamente contiene lo necesario para la ejecución de la aplicación. Como la aplicación se ejecuta dentro del entorno del contenedor, podemos usar la aplicación en cualquier sistema operativo siempre y cuando dispongamos de Docker\footnote{Docker \url{https://www.docker.com/}}.

La imagen de docker son construidos mediante un fichero 
DockerFile. En este documento viene las especificaciones técnicas que debe tener el entorno como las librerías que debe tener y las configuraciones de la imagen.A partir de esa imagen se construye contenedores donde podemos ejecutar el programa.

El programa tiene una estructura de clases como se muestra en la figura \ref{fig:UML}.
\begin{figure}[H]
	\centering
	\includegraphics[width = 1\textwidth]{Imagenes/TFGUml.pdf}
	\caption{Diagrama de clases de la herramienta.}
	\label{fig:UML}
\end{figure}
\section{Módulo de entrada}
Este es el módulo donde estará el programa principal donde se encarga de recibir los argumentos del usuario, parsear los argumentos, parsear los datos de configuración y llamar a los módulos de OCR y tests.
En el programa principal recibirá como parámetro:
\begin{itemize}
	\item --train. Para entrenar un modelo y se necesitará otros parametros para el entreno:
	\begin{itemize}
		\item -f font. Para especificar la fuente.
		\item -l lan. Para especificar el lenguaje.
		\item -i iter. El número de iteraciones.
		\item --clear . Si se elimina el entreno anterior del mismo modelo.
	\end{itemize}
	\item --test. Para hacer el test dada un archivo de configuración -c config.
\end{itemize}
Estos datos son pasados a la clase LocalizationTests donde se parseará los argumentos. En caso de entreno llamará al OCR con la opción de entrenar. Se obtendrá información del archivo de configuración en el caso de hacer un test. Se encargará de llamar a los dos módulos para el reconocimiento de texto y comprobación de test. Una vez finalizado se encargará de escribir los resultados de la salida en formato json.
La clase de Localizationtests es la clase encargada de obtener los datos del usuario, llamar al módulo de OCR proporcionando los datos, una vez finalizada el reconocimiento de texto, Localizationtests se encarga de organizar la ejecución de los tests, escribiendo los resultados de cada test en un Json y este informe en Json se guardará en la ruta de salida y podrá ser interpretada a un html que se contará a detalle en la sección \ref{sec:Generación informe}.


A continuación se detalla la implementación de cada módulo.
\section{Implementación del modulo OCR}
\label{sec:Implementación del OCR}
En el modulo del OCR, tenemos principalmente dos partes, el entreno de modelo y el reconocimiento de texto. Para la librería de OCR, en este caso se ha elegido Tesseract que cumple nuestras necesidades en tiempo y en precisión. La evaluación de las librerias de OCR se describe en la sección \ref{sec:Evaluación_OCR}.
\subsection{Entrenamiento de modelo}
Para el entreno de modelo se ha usado la plantilla proporcionado por \cite{Joseda} donde se ha hecho el entreno usando la api de Tesseract en python. Para nuestro caso, hasta el día de la implementación, Tesseract no ha sacado ningún API para el entreno de modelo en \emph{C++}, por lo que en nuestra herramienta haremos llamadas al sistema con comandos proporcionado en la plantilla de \cite{Joseda} para el entreno de modelo.
\subsection{Reconocimiento de texto y mejoras}
Este módulo se ha diseñado pensando en su extensibilidad de modo que es posible usar otras librerías de OCR diferentes a la que se está usando la herramienta.
En este modulo es posible cambiar de libreria de OCR (p.ej EasyOCR) heredando de la clase virtual pura \texttt{OCR} y completando las funciones necesarias con métodos de esa librería sin afectar al funcionamiento completo de la herramienta. 

El proceso de reconocimiento y mejoras es la siguiente:
\begin{enumerate}
	\item  Recibidos parámetros del programa principal, este crea las carpetas correspondientes a la salida usando llamadas al sistema.
	\item Recorrerá la carpeta de imágenes preprocesando cada imagen con OpenCV.
	\item La imagen resultante del preprocesado será pasado a la librería de Tesseract para su reconocimiento de texto.
	\item Seguido de una limpieza de la salida de OCR usando la distancia Levenshtein en el caso de que el usuario haya proporcionado la salida esperada.
	\item  Al finalizar el proceso, escribirá la salida en el directorio de la salida con el formato \emph{nombre\_imagen.txt}.
\end{enumerate}
 
Para la recogida de parámetros, es necesario un archivo de configuración con el siguiente formato:
\begin{itemize}
	\item imagePath. Directorio donde se encuentra las imágenes.
	\item gtPath. Directorio donde se encuentra la cadena esperada de cada imagen.
   	\item model. Nombre del modelo que se va a usar.
	\item modelPath. Directorio donde se encuentra el modelo que se va a usar.
	\item outputPath. Directorio de salida de la información.
	\item OCR. El ocr que se va a usar. Por defecto Tesseract.
	\item placeholders. El placeholder que se usa. Debe tener un campo \texttt{begin} con la apertura del placeholder y un campo \texttt{end} con el cierre.
\end{itemize}

El preprocesado se ejecuta en el método protegido \texttt{preprocessing} de la clase \texttt{OCR}, la cual se usan métodos proporcionado por OpenCV de las cuales son:
\begin{itemize}
	\item \texttt{Resize}. Cambia las dimensiones la imagen, lo cual ajusta el tamaño de la imagen para un mejor reconocimiento.
	\item \texttt{Threshold} Aplica simple thresholding la cual asigna un valor binario a cada píxel dependiendo el umbral. Resalta mejor los caracteres del fondo.
	\item \texttt{fastNlMeansDenoising} Aplica reducción de ruido para mejorar la calidad visual y el reconocimiento.
	\item \texttt{medianBlur} y \texttt{GaussianBlur} Otra técnica para aplicar reducción de ruido suavizando la imagen.
	\item \texttt{dilate} y \texttt{erode} Técnica de dilatar y erosionar que ayuda a reducir ruidos y el cierre de contornos, mejora la detección de los caracteres.
\end{itemize}
La combinación anterior se ha obtenido haciendo estudio y experimento sobre las técnicas de preprocesamiento en la sección \ref{sec:Mejoras en el reconocimiento}

El siguiente paso es el reconocimiento de texto utilizando la librería de Tesseract. El método \texttt{getDirImgText} para reconocer texto de una carpeta de imágenes se sitúa en la clase \texttt{OCR}, la cual es un método virtual puro que en la clase de \texttt{Tesseract} debe implementar. En el método se hace lo siguiente: 
\begin{enumerate}
	\item Genera las carpetas de salida relacionado al reconocimiento utilizando llamadas al sistema y dando permisos de escritura a la carpeta.
	\item Abre el directorio de carpetas con \texttt{opendir} y obteniendo la información en \texttt{dirent}, para obtener los nombres de los archivos y filtrar aquellas que son imágenes en formato png.
	\item Ejecutará el preprocesamiento de cada imagen con las técnicas anteriores.
	\item La imagen resultante será pasado al OCR con \texttt{SetImage} de Tesseract.
	\item Se obtendrá el texto reconocido con \texttt{GetUTF8Text} de Tesseract.
	\item Se hace la limpieza de caracteres utilizando distancia Levenshtein y se escribe en la salida el resultado.
\end{enumerate}
La limpieza se hace porque el OCR puede devolver caractéres basura(p.ej reconoce una caja del fondo como un carácter), y esta basura afecta a la detección de errores. Para resolver este problema se utiliza la distancia Levenshtein, una métrica que calcula el grado de diferencia entre dos cadenas de texto con la idea de quedarnos con aquellas líneas reconocidas donde más se parezca a nuestra cadena esperada. 
La limpieza se hace con el método \texttt{findMostSimilarLine} de la clase \texttt{OCR}, lo que hace es calcular el valor de similitud de las cadenas utilizando la distancia Levenshtein y si supera un cierto umbral que definimos, entonces se considera la línea.Más detalles de investigación y evaluación se encuentra en la sección \ref{subsec:Eliminación de caracter basura}.

Tesseract también se encarga de devolver las coordenadas del texto en la imagen si es necesario, para ello, la información lo podemos encontrar en el método \texttt{BoundingBox} del \texttt{ResultIterator} de Tesseract. Los detalles de implementación se ha descrito en el test \ref{itest:overlap} que hará uso de esta función.

También usamos OpenCV para el reconocimiento del contorno de la caja delimitadora para el error de solapamiento de texto. Utilizando \texttt{findContours} para encontrar el contorno y \texttt{approxPolyDP} para el filtrado de contornos ya que solo nos quedamos con los rectángulos. Los detalles de implementación se ha descrito en el test \ref{itest:overlap} que hará uso de esta función.

\section{Implementación del modulo test}
\label{sec:Implementación de los tests}

Este módulo también se ha diseñado pensando en su extensibilidad.
En este modulo, los tests heredan de la clase TestCases por lo que es posible implementar más tests de los que hay implementado sin afectar el funcionamiento general de la herramienta.
\subsection{Test sobre solapamiento de texto}
\label{itest:overlap}
Este test está implementado en la clase \texttt{Overlap}.
Para la implementación de este test se ha hecho el uso de Tesseract para obtener las coordenadas del texto en la imagen, además se hace el uso de OpenCV para la detección de la caja delimitadora del texto y la obtención de las coordenadas en la imagen.

La implementación de obtención de coordenadas del texto mediante Tesseract se sitúa en el módulo de OCR en la clase \texttt{Tesseract} en el método \texttt{getBoundingBoxes} la cual devuelve un vector de todas las cajas de texto. Para la implementación de este método, se usa \texttt{Pix} para leer la imagen, seguido del reconocimiento de texto de Tesseract. Una vez reconocido el texto, se usa el \texttt{ResultIterator} de Tesseract para iterar sobre los resultados donde se puede obtener las cajas de los textos utilizando el método \texttt{BoundingBox} de la clase \texttt{ResultIterator} de Tesseract.

La implementación de obtención de coordenadas de la caja delimitadora también se ha hecho en el módulo de OCR. En la propia clase \texttt{OCR} existe un método llamado \texttt{getButtonsFromImage}. Para la implementación de este método se hace uso de OpenCV siguiendo estos pasos:
\begin{enumerate}
	\item Se lee la imagen con \texttt{imread}.
	\item Se pasa a grises con \texttt{cvtColor}
	\item Se detecta los bordes con gradientes utilizando \texttt{canny}. Los gradientes es lo que mide cuán rápido cambia la intensidad del píxel respecto a sus vecinos.
	\item Se obtiene los contornos con \texttt{findContours}
	\item Se busca los contornos de forma de cuadrado utilizando \texttt{approxPolyDP} y obtenemos las coordenadas de una posible caja delimitadora.
\end{enumerate}

Se comparan ambas coordenadas comprobando que parte del texto está dentro de la caja delimitadora y parte esta fuera de esa caja, por lo que se considera que existe un solapamiento de texto. En el test se puede especificar un tamaño mínimo de la caja delimitadora para que OpenCV ignore todos los contornos menores a ello. 
\subsection{Test sobre implementación incorrecta}
\label{itest:placeholder}
Este test está implementado en la clase \texttt{Placeholders}.
Para la implementación de este test se obtiene los delimitadores de placeholder que se especifica en el archivo de configuración con su apertura y cierre. Después se hace el uso de expresiones regulares para la detección de subcadenas donde existan placeholder. Según \cite{Regex} define las expresiones regulares como una cadena genérica que se usa a modo de patrón y que sirve para localizar texto dentro de un texto mayor. 

En nuestro caso usaremos el regex proporcionado en \emph{C++} y el patrón es la siguiente:

\verb|std::wstring pattern = L"\\" + inicio + L"(.*?)" +L"\\" +  fin;|

Donde ``inicio'' es la cadena de apertura del placeholder y ``fin'' es la cadena de cierre del placeholder. 

Debido a que las caractéres con tilde ocupan más de un byte en la codificación de UTF-8 por lo que al encontrarse con un carácter con tilde se cuanta dos posiciones. Por tanto utilizaremos wstring que es la clase de string utilizando wide char, esto resolverá el problema de conteo de posiciones.

Antes de hacer la búsqueda, cambiaremos de utf-8 a wstring utilizando el método \texttt{utf8\_to\_wstring} de la misma clase, la cual lo que hace es pasar de utf-8 a unicode utilizando ICU (\textit{International Components for Unicode}) y luego pasarlo a wstring. El método \texttt{wstring\_to\_utf8} hace lo mismo pero de forma contraria.

Construimos la expresión regular con \texttt{wregex} utilizando el patrón, con la expresión empezamos la búsqueda en el texto reconocido por el OCR utilizando \texttt{regex\_search} y guardando los resultados en la clase \texttt{wsmatch} de regex, obteniendo así la posición con \texttt{position} de la clase \texttt{wsmatch} y el contenido del placeholder con \texttt{str} de \texttt{wsmatch}.


\subsection{Test sobre truncamiento de texto}
\label{itest:truncamiento}
Este test está implementado en la clase \texttt{Truncation}.
Para la implementación de este test es necesario tener la cadena esperada. Se compara el número de caracteres de la cadena esperada y la cadena reconocida por el OCR usando \texttt{.length} del \texttt{string} de la std, en el caso de que sean iguales, no hay forma de que exista un truncamiento por lo que pasa el test.
Si la longitud de las dos cadenas son diferentes, se compara palabra a palabra de la cadena esperada y de la cadena reconocida, si una es subcadena de otra, es decir que una contiene a la otra utilizando el método \texttt{substr} del \texttt{string}. Cada palabra que coincidan o que se detecte como subcadena de otra serán descartadas del bucle de comparación.

Si al final del bucle aun queda cadenas sin comparar, eso significa que falta palabras, por lo que es un truncamiento a nivel de frase.
\section{Generación de informe}
\label{sec:Generación informe}
Una vez terminado el proceso de reconocimiento y detección de errores de localización con los test, la clase \texttt{LocalizationTests} genera un Json con el siguiente formato:
\begin{verbatim}
	"nombre_imagen.png": {
		"tests": {
			"overall_pass": false,
			"overlap": {
				"test_pass": false
			},
			"placeholders": {
				"test_pass": false,
				"errors":[{
					"pos":20
					"contenido": &_placeholder_&
				}]
			},
			"similarity": 22.69503546099291,
			"truncamiento": {
				"test_pass": false
			}
		},
		"texto_esperado": texto
		"texto_reconocido": texto
	}
\end{verbatim}
Tendrá el nombre de la imagen, seguido del texto esperado y texto reconocido. Indicará en el campo de \texttt{tests} el resultado de cada test con un booleano en el campo \texttt{test\_pass} y si tiene información extra como los \texttt{pos} y \texttt{contenido} cuando hay un error de placeholder. Un campo \texttt{overall\_pass} que indica si pasa todos los test o falla en alguno y un campo \texttt{similarity} que indica el porcentaje de similitud entre la cadena esperada y el reconocido.

Para la generación del informe, es necesario tener una carpeta json en la carpeta donde se sitúa las imágenes, donde tendrá todo el contenido relacionado a la generación de informe. Para la generación de informe se ha hecho el uso de handlebars que permite generar html a partir de una plantilla. Se tiene que seguir estos pasos para generar el informe:
\begin{enumerate}
	\item Es necesario tener ``node'' instalado en la computadora.
	\item Llevar el archivo \textit{result.json} a la carpeta json.
	\item Abrir cmd o powershell y ejecutar el comando ``node generateHtml.js''.
	\item Se generará el informe en output.html
\end{enumerate}
\section{Despliegue}
Como se comenta al principio de este capítulo, esta aplicación se despliega en un contenedor de docker pensando que la herramienta se pueda ejecutar en cualquier sistema siempre y cuando se disponga de docker.
Existirá dos formas de ejecutar la herramienta dependiendo de la necesidad.

Si se hace uso de la herramienta directamente:
\texttt{(Se explica aqui los detalles para usar la herramienta.)}

Si se desea hacer una extensión de la herramienta como añadir más tests o usar una librería de OCR diferente,el proceso será:
\begin{enumerate}
	\item Construir la imagen usando el DockerFile proporcionado.
	\item Arrancar el contenedor con la imagen construida.
	\item Abril visual studio 2022 u otro editor y conectarse al contenedor.
	\item Ejecutar el programa y conseguir los resultados.
\end{enumerate}
Las instrucciones concretas se encuentran en el README.md .
Para el entreno del modelo con fuentes propias es necesario que esté la fuente en la carpeta fonts antes de la construcción de la imagen. Si se desea añadir más fuente posteriormente, existe un archivo con los pasos a seguir en el README.md .


\section{Conclusión}
La herramienta se despliega en un contenedor Docker y está implementado en \emph{C++}. El modulo de OCR usa Tesseract como librería de reconocimiento de texto y OpenCV para preprocesado y detección de contornos, el modulo acepta otras librerías de OCR con heredar de la clase OCR y implementando las funciones necesarias.Los tests también son extensibles añadiendo más tests heredando de la clase TestCases.

